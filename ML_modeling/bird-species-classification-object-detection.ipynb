{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load, inspect and prepare data\n","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf \nimport matplotlib.pyplot as plt\nimport cv2 as cv","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:15:09.134697Z","iopub.execute_input":"2022-08-23T12:15:09.135496Z","iopub.status.idle":"2022-08-23T12:15:10.785419Z","shell.execute_reply.started":"2022-08-23T12:15:09.135414Z","shell.execute_reply":"2022-08-23T12:15:10.784423Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Define train and test directories\ndataset_dir = \"../input/100-bird-species\"\n\ntrain_dir = dataset_dir + \"/\" + \"train\"\ntest_dir = dataset_dir + \"/\" + \"test\"\nvalid_dir = dataset_dir + \"/\" + \"valid\"\n\ntrain_dir, test_dir, valid_dir","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:15:10.786947Z","iopub.execute_input":"2022-08-23T12:15:10.787835Z","iopub.status.idle":"2022-08-23T12:15:10.796648Z","shell.execute_reply.started":"2022-08-23T12:15:10.787794Z","shell.execute_reply":"2022-08-23T12:15:10.795686Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# load data using tensorflow ImageDataGenerator class\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# ImageDataGenerator instance\ndata_generator = ImageDataGenerator(rescale = 1/255.0)\n\nIMG_SIZE = (224, 224) # all images in Bird Species dataset have size of 224x224\n\n# Load train and test images from directories\ntrain_dataset = data_generator.flow_from_directory(train_dir,\n                                                  target_size = IMG_SIZE\n                                                  )\ntest_dataset = data_generator.flow_from_directory(test_dir,\n                                                  target_size = IMG_SIZE\n                                                  )\nvalid_dataset = data_generator.flow_from_directory(valid_dir,\n                                                  target_size = IMG_SIZE\n                                                  )","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:15:10.798239Z","iopub.execute_input":"2022-08-23T12:15:10.798902Z","iopub.status.idle":"2022-08-23T12:15:14.933711Z","shell.execute_reply.started":"2022-08-23T12:15:10.798865Z","shell.execute_reply":"2022-08-23T12:15:14.932656Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Get class names\nclass_names = train_dataset.class_indices\nclass_names = list(class_names.keys())","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:15:14.936190Z","iopub.execute_input":"2022-08-23T12:15:14.936773Z","iopub.status.idle":"2022-08-23T12:15:14.942663Z","shell.execute_reply.started":"2022-08-23T12:15:14.936733Z","shell.execute_reply":"2022-08-23T12:15:14.940999Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class_names","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:15:14.944024Z","iopub.execute_input":"2022-08-23T12:15:14.944682Z","iopub.status.idle":"2022-08-23T12:15:14.962454Z","shell.execute_reply.started":"2022-08-23T12:15:14.944639Z","shell.execute_reply":"2022-08-23T12:15:14.961341Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# View some samples from dataset\n# get single batch from dataset\ndata_one_batch = train_dataset.next()  \nimages_one_batch = data_one_batch[0]      \n# labels are one-hot encoded, so we take argmax to get numerical representation\nclasses_one_batch = tf.argmax(data_one_batch[1], axis = 1)  \n\n\nplt.figure(figsize = (16,8))\nfor n, image in enumerate(images_one_batch):\n  plt.subplot(4, 8, n+1)\n  plt.imshow(image)\n  plt.title(class_names[classes_one_batch[n]], fontdict = {'fontsize' : 8})\n  plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:15:14.963736Z","iopub.execute_input":"2022-08-23T12:15:14.965029Z","iopub.status.idle":"2022-08-23T12:15:17.756654Z","shell.execute_reply.started":"2022-08-23T12:15:14.964992Z","shell.execute_reply":"2022-08-23T12:15:17.754005Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Transfer learning using EffecientNetB0\n\nCreating and training model using EfficientNetB0 baseline from Tensorflow Hub","metadata":{}},{"cell_type":"code","source":"import tensorflow_hub as hub\n\nbaseline = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\",\n           trainable=False) # we're not training baseline model's layers to prevent overfitting","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:15:17.757618Z","iopub.execute_input":"2022-08-23T12:15:17.757928Z","iopub.status.idle":"2022-08-23T12:15:22.422504Z","shell.execute_reply.started":"2022-08-23T12:15:17.757898Z","shell.execute_reply":"2022-08-23T12:15:22.421464Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# set random seed\ntf.random.set_seed(42)\n\n# create the model using sequential API\nmodel = tf.keras.Sequential([\n      # Data augmentation\n      tf.keras.layers.RandomFlip(\"horizontal\"),\n      tf.keras.layers.RandomZoom((-0.3, 0.3), (-0.3, 0.3)),\n      ###################\n      baseline,\n      tf.keras.layers.Dense(len(class_names), activation = \"softmax\")\n])\n\n# compile the model\nmodel.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n              loss = tf.keras.losses.categorical_crossentropy,\n              metrics = [\"accuracy\"])\n\n# fit the model\nhistory_0 = model.fit(train_dataset,\n                      epochs = 7,\n                      validation_data = valid_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:15:22.425197Z","iopub.execute_input":"2022-08-23T12:15:22.425588Z","iopub.status.idle":"2022-08-23T12:35:16.485376Z","shell.execute_reply.started":"2022-08-23T12:15:22.425531Z","shell.execute_reply":"2022-08-23T12:35:16.484400Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Let's try fine-tuning to improve our model. for this, we will make the baseline model's layers trainable","metadata":{}},{"cell_type":"code","source":"model.layers[2].trainable = True","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:35:16.488077Z","iopub.execute_input":"2022-08-23T12:35:16.489030Z","iopub.status.idle":"2022-08-23T12:35:16.493879Z","shell.execute_reply.started":"2022-08-23T12:35:16.488987Z","shell.execute_reply":"2022-08-23T12:35:16.492836Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# recompile the model\nmodel.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001), # use lower learning rate when fine-tuning\n              loss = tf.keras.losses.categorical_crossentropy,\n              metrics = [\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:35:16.495733Z","iopub.execute_input":"2022-08-23T12:35:16.496910Z","iopub.status.idle":"2022-08-23T12:35:16.509778Z","shell.execute_reply.started":"2022-08-23T12:35:16.496869Z","shell.execute_reply":"2022-08-23T12:35:16.508808Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# fit the model\nhistory_1 = model.fit(train_dataset,\n                      epochs = 10,\n                      validation_data = valid_dataset,\n                      initial_epoch = 7)","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:35:16.512236Z","iopub.execute_input":"2022-08-23T12:35:16.512951Z","iopub.status.idle":"2022-08-23T12:47:09.730924Z","shell.execute_reply.started":"2022-08-23T12:35:16.512889Z","shell.execute_reply":"2022-08-23T12:47:09.729858Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Plot loss and accuracy curves\n\n# Before fine-tuning\nval_loss_before_ft = history_0.history['val_loss']\nval_acc_before_ft = history_0.history['val_accuracy']\n\n# During fine-tuning\nval_loss_during_ft = history_1.history['val_loss']\nval_acc_during_ft = history_1.history['val_accuracy']\n\n\nplt.figure(figsize = (20, 10))\nplt.subplot(1, 2, 1)\nplt.plot(np.arange(1, len(val_loss_before_ft) + 1), val_loss_before_ft)\nplt.plot(np.arange(len(val_loss_before_ft) + 1, len(val_loss_before_ft) + len(val_loss_during_ft) + 1), \n                   val_loss_during_ft)\n\nplt.legend(['before fine-tuning', 'during fine-tuning'])\nplt.xlabel('epoch')\nplt.ylabel('loss')\n\nplt.subplot(1, 2, 2)\nplt.plot(np.arange(1, len(val_acc_before_ft) + 1), val_acc_before_ft)\nplt.plot(np.arange(len(val_acc_before_ft) + 1, len(val_acc_before_ft) + len(val_acc_during_ft) + 1), \n                   val_acc_during_ft)\n\nplt.legend(['before fine-tuning', 'during fine-tuning'])\nplt.xlabel('epoch')\nplt.ylabel('accuracy')","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:47:09.733573Z","iopub.execute_input":"2022-08-23T12:47:09.733984Z","iopub.status.idle":"2022-08-23T12:47:10.096162Z","shell.execute_reply.started":"2022-08-23T12:47:09.733930Z","shell.execute_reply":"2022-08-23T12:47:10.095271Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# evaluate model on test data\nmodel.evaluate(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:47:21.085792Z","iopub.execute_input":"2022-08-23T12:47:21.086432Z","iopub.status.idle":"2022-08-23T12:47:26.495413Z","shell.execute_reply.started":"2022-08-23T12:47:21.086395Z","shell.execute_reply":"2022-08-23T12:47:26.494488Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# save model\nmodel.save(\"./400_bird_species_EFFNetB0\")","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:47:36.755764Z","iopub.execute_input":"2022-08-23T12:47:36.756497Z","iopub.status.idle":"2022-08-23T12:47:51.379481Z","shell.execute_reply.started":"2022-08-23T12:47:36.756460Z","shell.execute_reply":"2022-08-23T12:47:51.378455Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# test saved model\nloaded_model = tf.keras.models.load_model('./400_bird_species_EFFNetB0')\nloaded_model.evaluate(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:47:58.532278Z","iopub.execute_input":"2022-08-23T12:47:58.532851Z","iopub.status.idle":"2022-08-23T12:48:15.103436Z","shell.execute_reply.started":"2022-08-23T12:47:58.532813Z","shell.execute_reply":"2022-08-23T12:48:15.102510Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('download', 'zip', './400_bird_species_EFFNetB0')","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:48:21.167098Z","iopub.execute_input":"2022-08-23T12:48:21.167692Z","iopub.status.idle":"2022-08-23T12:48:25.732697Z","shell.execute_reply.started":"2022-08-23T12:48:21.167648Z","shell.execute_reply":"2022-08-23T12:48:25.731719Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Analyze model predictions on test data","metadata":{}},{"cell_type":"code","source":"# get model predictions and true labels\nimport numpy as np\n\nimages = []\ntrue_labels = []\npredictions = []\n\nfor n in range(len(test_dataset)):\n  image_batch, label_batch = test_dataset.next()\n  images.append(image_batch)\n  true_labels.append(tf.argmax(label_batch, axis = 1))\n  predictions.append(tf.argmax(model.predict(image_batch), axis = 1))\n\nimages = np.concatenate(images)\ntrue_labels = np.concatenate(true_labels)\npredictions = np.concatenate(predictions)","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:48:35.387719Z","iopub.execute_input":"2022-08-23T12:48:35.388131Z","iopub.status.idle":"2022-08-23T12:48:48.963622Z","shell.execute_reply.started":"2022-08-23T12:48:35.388096Z","shell.execute_reply":"2022-08-23T12:48:48.962578Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# get wrong predictions\nmask = true_labels != predictions\nimages = images[mask]\ntrue_labels = true_labels[mask]\npredictions = predictions[mask]\n\nlen(images), len(true_labels), len(predictions)","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:49:03.714794Z","iopub.execute_input":"2022-08-23T12:49:03.715615Z","iopub.status.idle":"2022-08-23T12:49:03.745889Z","shell.execute_reply.started":"2022-08-23T12:49:03.715572Z","shell.execute_reply":"2022-08-23T12:49:03.744954Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# visualize wrong predictions\n\nplt.figure(figsize =  (25, 20))\nfor n, image in enumerate(images):\n  plt.subplot(4, 5, n+1)\n  plt.imshow(image)\n  plt.title(f\"y_true:{class_names[true_labels[n]]},\\ny_pred:{class_names[predictions[n]]}\", fontdict = {\"fontsize\" : 9})\n  plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:49:45.792554Z","iopub.execute_input":"2022-08-23T12:49:45.792933Z","iopub.status.idle":"2022-08-23T12:49:48.195186Z","shell.execute_reply.started":"2022-08-23T12:49:45.792900Z","shell.execute_reply":"2022-08-23T12:49:48.194155Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Integrating with object detection model to detect different bird species in an image\n\nWe have built a classifier that can determine what species does the bird belong to based on it's image.\n\nIt will also be interesting to integrate this model to the existing object detector that can find birds in images. The resulting system will not only detect birds, but will also identify their species.\n\n","metadata":{}},{"cell_type":"markdown","source":"# Step 1: Bird detector\n\nFor this we will use pretrained object detection model EfficientDet-D2 from Tensorflow Hub.\n\nThis model was trained on COCO 2017 dataset where class number 16 is bird.","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:44:55.856082Z","iopub.execute_input":"2022-08-22T13:44:55.856851Z","iopub.status.idle":"2022-08-22T13:44:55.863429Z","shell.execute_reply.started":"2022-08-22T13:44:55.856810Z","shell.execute_reply":"2022-08-22T13:44:55.861895Z"}}},{"cell_type":"code","source":"import tensorflow_hub as hub\n\ndetector = hub.load(\"https://tfhub.dev/tensorflow/efficientdet/d2/1\")","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:51:40.639176Z","iopub.execute_input":"2022-08-23T12:51:40.639856Z","iopub.status.idle":"2022-08-23T12:52:17.211854Z","shell.execute_reply.started":"2022-08-23T12:51:40.639819Z","shell.execute_reply":"2022-08-23T12:52:17.210797Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"Let's create a function that will use this model to extract birds from an image and return their coordinates.","metadata":{}},{"cell_type":"code","source":"def extract_bird_roi(model, image, threshold = 0.5):\n  # get image dimensions\n  width, height = image.shape[0], image.shape[1]\n\n  # perform object detection\n  detector_output = model(np.expand_dims(image, axis = 0))\n\n  # bird class is 16th in the coco dataset\n  bird_mask = detector_output[\"detection_classes\"] == 16\n  # apply threshold\n  bird_mask = (detector_output[\"detection_scores\"] > threshold) & bird_mask\n  bird_boxes = detector_output[\"detection_boxes\"][bird_mask]\n\n\n  bird_images = []\n  # this will be a list of tuples with pair: \n  # ROI (Region Of Interest), Box coordinates\n  \n  # extract ROI and coordinates for each detected bird\n  for box in bird_boxes:\n    min_corner = (int(box[1] * height), int(box[0] * width))\n    max_corner = (int(box[3] * height), int(box[2] * width))\n    bird_images.append((image[min_corner[1] : max_corner[1], min_corner[0] : max_corner[0]],  \n                        (min_corner, max_corner)))\n  \n  return bird_images\n","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:52:31.794990Z","iopub.execute_input":"2022-08-23T12:52:31.795732Z","iopub.status.idle":"2022-08-23T12:52:31.803506Z","shell.execute_reply.started":"2022-08-23T12:52:31.795695Z","shell.execute_reply":"2022-08-23T12:52:31.802212Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"To test this function we will use the following image of ostriches. Source: https://www.livescience.com/biggest-birds-on-earth (Image credit: Getty Images)","metadata":{}},{"cell_type":"code","source":"ostriches_image = plt.imread(\"../input/bird-photos/ostriches.jpg\")\nplt.imshow(ostriches_image)\nplt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:52:45.712708Z","iopub.execute_input":"2022-08-23T12:52:45.713149Z","iopub.status.idle":"2022-08-23T12:52:45.995183Z","shell.execute_reply.started":"2022-08-23T12:52:45.713105Z","shell.execute_reply":"2022-08-23T12:52:45.991969Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"rois = extract_bird_roi(detector, ostriches_image, threshold = 0.5)\n\nplt.figure(figsize = (10, 10))\n\nplt.subplot(2, 2, 1)\nplt.imshow(rois[0][0])\nplt.subplot(2, 2, 2)\nplt.imshow(rois[1][0])\nplt.subplot(2, 2, 3)\nplt.imshow(rois[2][0])\nplt.subplot(2, 2, 4)\nplt.imshow(rois[3][0])","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:52:51.020110Z","iopub.execute_input":"2022-08-23T12:52:51.020558Z","iopub.status.idle":"2022-08-23T12:52:57.362662Z","shell.execute_reply.started":"2022-08-23T12:52:51.020522Z","shell.execute_reply":"2022-08-23T12:52:57.361861Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"Let's test for another image.","metadata":{}},{"cell_type":"code","source":"pigeons_image = plt.imread(\"../input/bird-photos/Domestic_Pigeon_Flock.jpg\")\nplt.imshow(pigeons_image)\nplt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:53:11.440507Z","iopub.execute_input":"2022-08-23T12:53:11.440915Z","iopub.status.idle":"2022-08-23T12:53:11.691795Z","shell.execute_reply.started":"2022-08-23T12:53:11.440878Z","shell.execute_reply":"2022-08-23T12:53:11.690857Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"Source: https://en.wikipedia.org/wiki/Bird_flight#/media/File:Domestic_Pigeon_Flock.jpg Author: Toby Hudson|","metadata":{}},{"cell_type":"code","source":"rois = extract_bird_roi(detector, pigeons_image, threshold = 0.5)\n\nplt.figure(figsize = (10, 10))\n\nplt.subplot(2, 2, 1)\nplt.imshow(rois[0][0])\nplt.subplot(2, 2, 2)\nplt.imshow(rois[1][0])\nplt.subplot(2, 2, 3)\nplt.imshow(rois[2][0])\nplt.subplot(2, 2, 4)\nplt.imshow(rois[3][0])","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:53:14.433000Z","iopub.execute_input":"2022-08-23T12:53:14.434071Z","iopub.status.idle":"2022-08-23T12:53:15.449606Z","shell.execute_reply.started":"2022-08-23T12:53:14.434010Z","shell.execute_reply":"2022-08-23T12:53:15.448608Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Step 2: Integrate Species Classifier with the Bird Detector\n\nNow we will create a function that takes regions of interest obtained from the previous model and uses bird classifier to predict species of birds present in those regions.\n\nWe will also draw bounding boxes on an image and print corresponting bird species in them.","metadata":{}},{"cell_type":"code","source":"rois = extract_bird_roi(detector, ostriches_image, threshold = 0.5)\n\ndef identify_species(model, rois):\n    \n    predictions = [] # list of bird species identified\n    \n    for roi in rois:\n        roi_resized = tf.image.resize(roi[0] / 255.0, (224, 224))\n        prediction = tf.argmax(model.predict(tf.expand_dims(roi_resized, axis = 0)), axis = 1)\n        predictions.append((class_names[int(prediction)]))\n\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:53:21.224608Z","iopub.execute_input":"2022-08-23T12:53:21.225262Z","iopub.status.idle":"2022-08-23T12:53:21.658432Z","shell.execute_reply.started":"2022-08-23T12:53:21.225223Z","shell.execute_reply":"2022-08-23T12:53:21.657415Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"identify_species(model = model, rois = rois)","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:53:23.996856Z","iopub.execute_input":"2022-08-23T12:53:23.997495Z","iopub.status.idle":"2022-08-23T12:53:24.379422Z","shell.execute_reply.started":"2022-08-23T12:53:23.997459Z","shell.execute_reply":"2022-08-23T12:53:24.378462Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"Let's build a function to draw bounding boxes with text","metadata":{}},{"cell_type":"code","source":"def draw_bounding_boxes_with_text(image, rois, predictions):\n    image_copy = image.copy()\n    \n    for n, roi in enumerate(rois):\n        cv.rectangle(image_copy, roi[1][0], roi[1][1], (0, 255, 0))\n        cv.putText(image_copy, predictions[n], roi[1][0], \n                   cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n    \n    return image_copy","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:53:32.024907Z","iopub.execute_input":"2022-08-23T12:53:32.025574Z","iopub.status.idle":"2022-08-23T12:53:32.032319Z","shell.execute_reply.started":"2022-08-23T12:53:32.025526Z","shell.execute_reply":"2022-08-23T12:53:32.031204Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10, 10))\nplt.imshow(draw_bounding_boxes_with_text(image = ostriches_image, rois = rois, \n                                         predictions = identify_species(model = model, rois = rois)))","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:53:35.399682Z","iopub.execute_input":"2022-08-23T12:53:35.400085Z","iopub.status.idle":"2022-08-23T12:53:36.008831Z","shell.execute_reply.started":"2022-08-23T12:53:35.400044Z","shell.execute_reply":"2022-08-23T12:53:36.008008Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"Now we'll build a function that combines object detection and species identification","metadata":{}},{"cell_type":"code","source":"def detect_bird_species(image, bird_detector = detector, species_classifier = model):\n    # detect birds in the image\n    rois = extract_bird_roi(bird_detector, image, threshold = 0.5)\n    \n    # identify bird species\n    species = identify_species(species_classifier, rois)\n    \n    # draw bounding boxes and text\n    output_image = draw_bounding_boxes_with_text(image, rois, species)\n    \n    return output_image","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:54:27.952831Z","iopub.execute_input":"2022-08-23T12:54:27.953452Z","iopub.status.idle":"2022-08-23T12:54:27.962902Z","shell.execute_reply.started":"2022-08-23T12:54:27.953405Z","shell.execute_reply":"2022-08-23T12:54:27.961799Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15, 15))\nplt.imshow(detect_bird_species(ostriches_image))","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:54:30.656764Z","iopub.execute_input":"2022-08-23T12:54:30.657160Z","iopub.status.idle":"2022-08-23T12:54:31.800658Z","shell.execute_reply.started":"2022-08-23T12:54:30.657126Z","shell.execute_reply":"2022-08-23T12:54:31.799825Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"Let's try some other images","metadata":{}},{"cell_type":"code","source":"blue_bird = plt.imread(\"../input/bird-photos/blue_bird.jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:54:36.312410Z","iopub.execute_input":"2022-08-23T12:54:36.313548Z","iopub.status.idle":"2022-08-23T12:54:36.478391Z","shell.execute_reply.started":"2022-08-23T12:54:36.313498Z","shell.execute_reply":"2022-08-23T12:54:36.477360Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15, 15))\nplt.imshow(detect_bird_species(blue_bird))","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:54:38.801972Z","iopub.execute_input":"2022-08-23T12:54:38.804600Z","iopub.status.idle":"2022-08-23T12:54:40.494672Z","shell.execute_reply.started":"2022-08-23T12:54:38.804561Z","shell.execute_reply":"2022-08-23T12:54:40.493772Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Image source: https://www.birdwatchingdaily.com/news/birdwatching/birds-increase-human-happiness-study-finds/ A Mountain Bluebird in Alberta. Photo by David Mundy","metadata":{}},{"cell_type":"code","source":"three_birds = plt.imread(\"../input/bird-photos/three_birds.jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:55:23.862719Z","iopub.execute_input":"2022-08-23T12:55:23.863810Z","iopub.status.idle":"2022-08-23T12:55:23.897807Z","shell.execute_reply.started":"2022-08-23T12:55:23.863759Z","shell.execute_reply":"2022-08-23T12:55:23.896688Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15, 15))\nplt.imshow(detect_bird_species(three_birds))","metadata":{"execution":{"iopub.status.busy":"2022-08-23T12:55:27.034642Z","iopub.execute_input":"2022-08-23T12:55:27.035030Z","iopub.status.idle":"2022-08-23T12:55:28.321002Z","shell.execute_reply.started":"2022-08-23T12:55:27.034994Z","shell.execute_reply":"2022-08-23T12:55:28.320162Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"Image source: https://feederwatch.org/blog/2020-2021-birdspotter-grand-prize-winners/\n\n| Jelly Squabble! by Pam Garcia |","metadata":{}}]}